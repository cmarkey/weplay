{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assumed_danger_states_new</th>\n",
       "      <th>Max_Success</th>\n",
       "      <th>Max_Best</th>\n",
       "      <th>Max_Exp</th>\n",
       "      <th>Home_Plate_Control</th>\n",
       "      <th>Woman_Adv</th>\n",
       "      <th>OD_MST_Ratio</th>\n",
       "      <th>All_OCR</th>\n",
       "      <th>O_Avg_Edge</th>\n",
       "      <th>D_Avg_Edge</th>\n",
       "      <th>...</th>\n",
       "      <th>ScoreProb_p3</th>\n",
       "      <th>ScoreProb_p4</th>\n",
       "      <th>ScoreProb_p5</th>\n",
       "      <th>ScoreProb_p6</th>\n",
       "      <th>Exp_p1</th>\n",
       "      <th>Exp_p2</th>\n",
       "      <th>Exp_p3</th>\n",
       "      <th>Exp_p4</th>\n",
       "      <th>Exp_p5</th>\n",
       "      <th>Exp_p6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.274195</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>0.029651</td>\n",
       "      <td>-0.585296</td>\n",
       "      <td>-2</td>\n",
       "      <td>1.956106</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>25.426174</td>\n",
       "      <td>12.998359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.516279</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>-0.516093</td>\n",
       "      <td>1</td>\n",
       "      <td>1.719546</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>24.210186</td>\n",
       "      <td>14.079408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155717</td>\n",
       "      <td>0.089968</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>-0.010502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.756784</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.039369</td>\n",
       "      <td>-0.386730</td>\n",
       "      <td>1</td>\n",
       "      <td>2.005085</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>25.245765</td>\n",
       "      <td>12.590870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132135</td>\n",
       "      <td>0.045605</td>\n",
       "      <td>0.030886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.038993</td>\n",
       "      <td>0.015839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.778119</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>-0.407654</td>\n",
       "      <td>1</td>\n",
       "      <td>1.488252</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>25.988658</td>\n",
       "      <td>17.462536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095735</td>\n",
       "      <td>0.066797</td>\n",
       "      <td>0.021006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>0.028593</td>\n",
       "      <td>-0.014305</td>\n",
       "      <td>-0.007602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.687612</td>\n",
       "      <td>0.049012</td>\n",
       "      <td>0.111732</td>\n",
       "      <td>-0.314420</td>\n",
       "      <td>0</td>\n",
       "      <td>1.189590</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>22.851884</td>\n",
       "      <td>19.209889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237726</td>\n",
       "      <td>0.082992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.094022</td>\n",
       "      <td>-0.019252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   assumed_danger_states_new  Max_Success  Max_Best   Max_Exp  \\\n",
       "0                          0     0.274195  0.017804  0.029651   \n",
       "1                          0     0.516279  0.025508  0.031988   \n",
       "2                          0     0.756784  0.019947  0.039369   \n",
       "3                          0     0.778119  0.028621  0.037645   \n",
       "4                          0     0.687612  0.049012  0.111732   \n",
       "\n",
       "   Home_Plate_Control  Woman_Adv  OD_MST_Ratio   All_OCR  O_Avg_Edge  \\\n",
       "0           -0.585296         -2      1.956106  0.600000   25.426174   \n",
       "1           -0.516093          1      1.719546  0.750000   24.210186   \n",
       "2           -0.386730          1      2.005085  0.750000   25.245765   \n",
       "3           -0.407654          1      1.488252  0.875000   25.988658   \n",
       "4           -0.314420          0      1.189590  0.714286   22.851884   \n",
       "\n",
       "   D_Avg_Edge  ...  ScoreProb_p3  ScoreProb_p4  ScoreProb_p5  ScoreProb_p6  \\\n",
       "0   12.998359  ...      0.000000      0.000000      0.000000           0.0   \n",
       "1   14.079408  ...      0.155717      0.089968      0.034349           0.0   \n",
       "2   12.590870  ...      0.132135      0.045605      0.030886           0.0   \n",
       "3   17.462536  ...      0.095735      0.066797      0.021006           0.0   \n",
       "4   19.209889  ...      0.237726      0.082992      0.000000           0.0   \n",
       "\n",
       "   Exp_p1    Exp_p2    Exp_p3    Exp_p4    Exp_p5    Exp_p6  \n",
       "0     0.0  0.000000  0.000000  0.000000  0.000000  0.027242  \n",
       "1     0.0  0.000000  0.030999  0.030720  0.004306 -0.010502  \n",
       "2     0.0  0.021324  0.000000  0.010992  0.038993  0.015839  \n",
       "3     0.0  0.000000  0.037433  0.028593 -0.014305 -0.007602  \n",
       "4     0.0  0.000000  0.000000 -0.003617  0.094022 -0.019252  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data = pd.read_csv('data_2_model2.csv', sep = ',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3148148148148148 0.32934131736526945\n"
     ]
    }
   ],
   "source": [
    "# Separate target and features\n",
    "x, y = data.iloc[:,1:], data['assumed_danger_states_new']\n",
    "# Get train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=123)\n",
    "print(y_test.mean(), y_train.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [10, 20, 30, 40, 50, 60, None], 'min_samples_split': [2, 4, 6, 8], 'min_samples_leaf': [1, 2, 3, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 9)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 60, num = 6)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4,5]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      None],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 300, 400, 500,\n",
       "                                                         600, 700, 800, 900,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      None],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 300, 400, 500,\n",
       "                                                         600, 700, 800, 900,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      None],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                                        'min_samples_split': [2, 4, 6, 8],\n",
       "                                        'n_estimators': [200, 300, 400, 500,\n",
       "                                                         600, 700, 800, 900,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2962962962962963\n",
      "0.3148148148148148\n",
      "{'n_estimators': 600, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf_random.predict(x_test)\n",
    "print((1*(predictions>0.5)!=y_test).mean())\n",
    "print((0!=y_test).mean()) \n",
    "\n",
    "#0.19534883720930232 all vars\n",
    "#0.19069767441860466 small vars\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = RandomForestRegressor(n_estimators = rf_random.best_params_['n_estimators'], min_samples_split=rf_random.best_params_['min_samples_split'], min_samples_leaf = rf_random.best_params_['min_samples_leaf'], max_depth = rf_random.best_params_['max_depth'],random_state = 42)\n",
    "# Train the model on all data\n",
    "rf_final.fit(x, y)\n",
    "# save the model to disk\n",
    "pickle.dump(rf_final, open('finalized_rf_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the model from disk\n",
    "# loaded_rf = pickle.load(open('finalized_rf_model.pkl', 'rb'))\n",
    "# loaded_pred = loaded_rf.predict(x_test)\n",
    "# print((1*(loaded_pred>0.5)!=y_test).mean())\n",
    "# print((0!=y_test).mean()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62e8fc6f19db06c74b7386df3475d65e5ee514ef2c0d9dd3bfd98b0ae49b7cf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
